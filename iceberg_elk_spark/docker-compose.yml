version: "3.8"

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - iceberg_net

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      #- "9092:9092"
      - "9092:9092"
      - "29092:29092"
    networks:
      - iceberg_net
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      # optional - enable topic auto create
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      # KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8082:8080"
    networks:
      - iceberg_net
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.1
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"

  aws:
    image: amazon/aws-cli
    hostname: aws-cli
    container_name: aws-cli
    volumes:
      - ./data:/home/data
    command: |
      -c "sleep 2"
#       /bin/bash -c "sleep 2 && 
#       aws s3 mb s3://warehouse --endpoint-url http://minio:9000 || exit 0"
#      /bin/bash -c "sleep 5 && \
#      aws --endpoint-url http://minio:9000 s3 mb s3://warehouse --region us-east-1 && \
#      aws --endpoint-url http://minio:9000 s3 cp /home/data s3://warehouse/raw --recursive"
    entrypoint: [/bin/bash]
    environment: 
      AWS_ACCESS_KEY_ID: "minioadmin"
      AWS_SECRET_ACCESS_KEY: "minioadmin"
      AWS_REGION: us-east-1
    depends_on: 
      - minio

  postgres:
    image: postgres:13
    container_name: postgres
    restart: always
    ports:
      - "5432:5432"
    networks:
      - iceberg_net
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore
    volumes:
      - postgres_data:/var/lib/postgresql/data

  hive-metastore:
    image: apache/hive:4.0.1
    container_name: hive-metastore
    depends_on:
      - postgres
    environment:
      SERVICE_NAME: metastore
      HIVE_DB_TYPE: postgres
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      HIVE_METASTORE_URIS: thrift://hive-metastore:9083
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    ports:
      - "9083:9083"
    volumes:
      - ./conf/metastore-site.xml:/opt/apache-hive-metastore-4.0.1-bin/conf/metastore-site.xml:ro
      - postgres_data:/var/lib/postgresql/data

  trino:
    image: trinodb/trino:latest
    container_name: trino
    networks:
      - iceberg_net
    depends_on:
      - minio
      - hive-metastore
      - iceberg-rest
      #- mc
    ports:
      - "8080:8080"
    volumes:
      - ./conf/trino/catalog/:/etc/trino/catalog/
      - ./trino-config/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties:ro
      # - ./trino-config/jvm.config:/etc/trino/jvm.config:ro
      # - ./trino-config/config.properties:/etc/trino/config.properties:ro
      # - ./trino-config/catalog:/etc/trino/catalog:ro
      # - ./trino-config/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties:ro
      
  # spark:
    # image: bitnami/spark:latest
    # container_name: spark
    # depends_on:
      # - hive-metastore
      # - minio
      # - kafka
      # - elasticsearch
    # ports:
      # - "5050:5050"  # Spark UI
      # - "7077:7077"  # Spark Master
    # environment:
      # SPARK_MODE: master
      # SPARK_MASTER_HOST: spark
      # SPARK_MASTER_PORT: 7077
    # volumes:
      # - ./spark-conf:/opt/spark/conf
      # - spark_data:/opt/spark/work-dir

  # spark-worker:
    # image: bitnami/spark:latest
    # container_name: spark-worker
    # depends_on:
      # - spark
    # environment:
      # SPARK_MODE: worker
      # SPARK_MASTER_URL: spark://spark:7077
    # volumes:
      # - spark_data:/opt/spark/work-dir
    
  spark:
    image: tabulario/spark-iceberg
    container_name: spark-iceberg
    build: spark/
    networks:
      iceberg_net:
    depends_on:
      - iceberg-rest
      - minio
    volumes:
      - ./warehouse:/home/iceberg/warehouse
      - ./notebooks:/home/iceberg/notebooks/notebooks
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
      SPARK_DEFAULTS: |
        spark.sql.extensions                    org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
        spark.sql.catalog.iceberg               org.apache.iceberg.spark.SparkCatalog
        spark.sql.catalog.iceberg.catalog-impl  org.apache.iceberg.rest.RESTCatalog
        spark.sql.catalog.iceberg.uri           http://rest:8181
        spark.sql.catalog.iceberg.io-impl       org.apache.iceberg.aws.s3.S3FileIO
        spark.sql.catalog.iceberg.warehouse     s3://warehouse/wh/
        spark.sql.catalog.iceberg.s3.endpoint   http://minio:9000
        spark.sql.catalog.iceberg.s3.path-style-access  true
        spark.sql.defaultCatalog                iceberg
        spark.sql.catalogImplementation         in-memory
        spark.eventLog.enabled                  true
        spark.eventLog.dir                      /home/iceberg/spark-events
        spark.history.fs.logDirectory           /home/iceberg/spark-events
        spark.jars.packages                     org.apache.hadoop:hadoop-aws:3.2.0
        spark.hadoop.fs.s3a.access.key          minioadmin
        spark.hadoop.fs.s3a.secret.key          minioadmin
        spark.hadoop.fs.s3a.endpoint            http://minio:9000
        spark.hadoop.fs.s3a.path.style.access   true
        spark.executor.extraJavaOptions         -Dcom.amazonaws.services.s3.enableV4=true
        spark.driver.extraJavaOptions           -Dcom.amazonaws.services.s3.enableV4=true
    ports:
      - 9999:9999
      - 9090:9090
      - 10000:10000
      - 10001:10001
      
  glue:
    container_name: glue_jupyter
    image: amazon/aws-glue-libs:glue_libs_4.0.0_image_01
    command: /home/glue_user/jupyter/jupyter_start.sh && sudo chown -R 10000:10000 /home/glue_user/workspace/jupyter_workspace
    environment:
      - DISABLE_SSL=true
      - AWS_PROFILE=glue4
      - DATALAKE_FORMATS=hudi
      - AWS_REGION=us-east-1
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    ports:
      - "4040:4040"
      - "4041:4041"
      - "28080:18080"
      - "28081:18081"
      - "8998:8998"
      - "8888:8888"
    restart: always
    volumes:
      - ./notebooks:/home/glue_user/workspace/jupyter_workspace/

  iceberg-rest:
    image: tabulario/iceberg-rest:latest
    container_name: iceberg-rest
    ports:
      - "8181:8181"
    networks:
      - iceberg_net
    environment:
      AWS_ACCESS_KEY_ID: "minioadmin"
      AWS_SECRET_ACCESS_KEY: "minioadmin"
      AWS_REGION: us-east-1
      CATALOG_WAREHOUSE: s3://warehouse/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9000
      CATALOG_S3_PATH__STYLE__ACCESS: True
      #CATALOG_URI: jdbc:postgresql://postgres/metastore
      #CATALOG_JDBC_USER: hive
      #CATALOG_JDBC_PASSWORD: hive
      # AWS_REGION: us-east-1
      # S3_ENDPOINT: http://minio:9000
      # S3_PATH_STYLE_ACCESS: "true"
      # S3_BUCKET: warehouse
      # ICEBERG_CATALOG_WAREHOUSE: s3a://warehouse/
      # ICEBERG_CATALOG_TYPE: hive
      # ICEBERG_CATALOG_URI: thrift://hive-metastore:9083
      # ICEBERG_CATALOG_IO_IMPL: org.apache.iceberg.aws.s3.S3FileIO

  minio:
    image: minio/minio
    hostname: minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_DOMAIN=minio
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - minio_data:/data
      
  # mc:
    # depends_on:
      # - minio
    # image: minio/mc
    # container_name: mc
    # networks:
      # - iceberg_net
    # environment:
      # - AWS_ACCESS_KEY_ID=minioadmin
      # - AWS_SECRET_ACCESS_KEY=minioadmin
      # - AWS_REGION=us-east-1
    # entrypoint: >
      # /bin/sh -c "
      # until (/usr/bin/mc config host add minio http://minio:9000 minioadmin minioadmin) do echo '...waiting...' && sleep 1; done;
      # /usr/bin/mc rm -r --force minio/warehouse;
      # /usr/bin/mc mb minio/warehouse;
      # /usr/bin/mc policy set public minio/warehouse;
      # tail -f /dev/null"
     

networks:
  iceberg_net:
    name: iceberg_net
    driver: bridge
  
volumes:
  minio_data:
  postgres_data:
  spark_data:
  elastic_data:
