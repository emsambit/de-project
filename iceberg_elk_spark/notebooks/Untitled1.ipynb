{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051a6dc1-642e-44f4-bcf8-66fddae66278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>spark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:Unable to verify existence of default database: com.amazonaws.services.glue.model.AWSGlueException: The security token included in the request is invalid. (Service: AWSGlue; Status Code: 400; Error Code: UnrecognizedClientException; Request ID: 2c97c3b6-27f4-4f6d-b0b3-3bb282466c71; Proxy: null))\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:133)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:248)\n",
      "  at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:151)\n",
      "  at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:141)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:61)\n",
      "  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:121)\n",
      "  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:121)\n",
      "  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:290)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.namespaceExists(V2SessionCatalog.scala:224)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:43)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:103)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:224)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:114)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$7(SQLExecution.scala:139)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:224)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:139)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:245)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:138)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)\n",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:100)\n",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:96)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:615)\n",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:177)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:615)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:591)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:96)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:83)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:81)\n",
      "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:222)\n",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:102)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\n",
      "  ... 51 elided\n",
      "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:Unable to verify existence of default database: com.amazonaws.services.glue.model.AWSGlueException: The security token included in the request is invalid. (Service: AWSGlue; Status Code: 400; Error Code: UnrecognizedClientException; Request ID: 2c97c3b6-27f4-4f6d-b0b3-3bb282466c71; Proxy: null))\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1609)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1594)\n",
      "  at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:615)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:394)\n",
      "  at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:294)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:225)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:224)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:274)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:394)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:248)\n",
      "  at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:104)\n",
      "  ... 97 more\n",
      "Caused by: org.apache.hadoop.hive.metastore.api.MetaException: Unable to verify existence of default database: com.amazonaws.services.glue.model.AWSGlueException: The security token included in the request is invalid. (Service: AWSGlue; Status Code: 400; Error Code: UnrecognizedClientException; Request ID: 2c97c3b6-27f4-4f6d-b0b3-3bb282466c71; Proxy: null)\n",
      "  at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.doesDefaultDBExist(AWSCatalogMetastoreClient.java:244)\n",
      "  at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.<init>(AWSCatalogMetastoreClient.java:152)\n",
      "  at com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory.createMetaStoreClient(AWSGlueDataCatalogHiveClientFactory.java:20)\n",
      "  at org.apache.hadoop.hive.ql.metadata.HiveUtils.createMetaStoreClient(HiveUtils.java:507)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3856)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3836)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1605)\n",
      "  ... 109 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE DATABASE IF NOT EXISTS climate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee075591-2520-4267-af6d-36a7628ad36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
